{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398cb39e",
   "metadata": {},
   "source": [
    "\n",
    "# ml01 — California Housing Baseline (Brandon J)\n",
    "\n",
    "**Purpose.** Establish a transparent, defensible baseline for predicting California median house values using linear regression. The goal is *reproducibility, interpretability, and evaluation discipline*, not raw leaderboard performance.\n",
    "\n",
    "**Design choices (why this is defendable):**\n",
    "- Use the built‑in California Housing dataset (clean, standard benchmark).\n",
    "- Small, interpretable feature set (**MedInc**, **AveRooms**) to isolate signal from confounds.\n",
    "- Constant baseline (median) to contextualize metrics — otherwise an R² value is floating in space.\n",
    "- Stratified split by **target quantiles** so the test set reasonably mirrors the train distribution.\n",
    "- Metrics: R², MAE, RMSE + residual diagnostics and coefficient table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24beb373",
   "metadata": {},
   "source": [
    "## 0. Imports (pre-installed via `uv sync`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74106d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast, List\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import cast, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb078368",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Verify Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9866f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load as DataFrame/Series for immediate analysis\n",
    "X_df, y_ser = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X: pd.DataFrame = cast(pd.DataFrame, X_df)\n",
    "y: pd.Series = cast(pd.Series, y_ser)\n",
    "\n",
    "# Combine for quick inspection / plotting\n",
    "df: pd.DataFrame = X.copy()\n",
    "df[\"MedHouseVal\"] = y\n",
    "\n",
    "# Sanity checks that matter in practice\n",
    "assert not df.isnull().any().any(), \"Dataset unexpectedly contains missing values.\"\n",
    "assert df.select_dtypes(\"number\").shape[1] == df.shape[1], \"Non-numeric columns found.\"\n",
    "\n",
    "# Distribution check confirms we loaded what we think we loaded\n",
    "ax = df.hist(bins=30, figsize=(12, 8))\n",
    "plt.suptitle(\"Feature Distributions — California Housing\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0b281",
   "metadata": {},
   "source": [
    "## 2. Stratified Train/Test Split (by Target Deciles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratifying by target stabilizes metrics across different random seeds\n",
    "qbins = pd.qcut(df[\"MedHouseVal\"], q=10, duplicates=\"drop\")\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(df, qbins))\n",
    "\n",
    "train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "features: List[str] = [\"MedInc\", \"AveRooms\"]\n",
    "target: str = \"MedHouseVal\"\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cf94f",
   "metadata": {},
   "source": [
    "## 3. Baseline (Median) vs. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6873bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: \"do nothing smart\" model — essential for context\n",
    "baseline = DummyRegressor(strategy=\"median\")\n",
    "baseline.fit(X_train, y_train)\n",
    "y_base = baseline.predict(X_test)\n",
    "\n",
    "# Linear model: simple, interpretable, and a good pedagogical baseline\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d32e3c",
   "metadata": {},
   "source": [
    "## 4. Metric Reporting (R², MAE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(name: str, y_true: pd.Series, y_hat) -> dict:\n",
    "    r2 = r2_score(y_true, y_hat)\n",
    "    mae = mean_absolute_error(y_true, y_hat)\n",
    "    rmse = root_mean_squared_error(y_true, y_hat)\n",
    "    print(f\"{name:>10} | R²={r2:0.3f} | MAE={mae:0.3f} | RMSE={rmse:0.3f}\")\n",
    "    return {\"r2\": r2, \"mae\": mae, \"rmse\": rmse}\n",
    "\n",
    "\n",
    "print(\"Model Evaluation (Lower MAE/RMSE is better; Higher R² is better)\")\n",
    "m_base = report_metrics(\"Baseline\", y_test, y_base)\n",
    "m_lin = report_metrics(\"LinearRG\", y_test, y_pred)\n",
    "\n",
    "if m_base[\"mae\"] > 0:\n",
    "    mae_impr = 100 * (m_base[\"mae\"] - m_lin[\"mae\"]) / m_base[\"mae\"]\n",
    "    print(f\"→ MAE improvement vs baseline: {mae_impr:0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e54baf",
   "metadata": {},
   "source": [
    "## 5. Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03047ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(y_pred, residuals, s=10, alpha=0.6)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals (y - ŷ)\")\n",
    "plt.title(\"Residuals vs Predicted Values\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee32aa",
   "metadata": {},
   "source": [
    "## 6. Coefficient Table (Interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "coef_df = (\n",
    "    pd.DataFrame({\"Feature\": features, \"Coefficient\": model.coef_})\n",
    "    .assign(Intercept=model.intercept_)\n",
    "    .sort_values(\"Coefficient\", key=np.abs, ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45145ba1",
   "metadata": {},
   "source": [
    "## 7. Visual Validation — Actual vs Predicted (MedInc slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(test_df[\"MedInc\"], y_test, s=8, alpha=0.4, label=\"Actual\")\n",
    "plt.scatter(test_df[\"MedInc\"], y_pred, s=8, alpha=0.7, label=\"Predicted\")\n",
    "plt.xlabel(\"MedInc\")\n",
    "plt.ylabel(\"MedHouseVal\")\n",
    "plt.title(\"MedInc vs MedHouseVal — Actual vs Predicted\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
